# ML-Chain v3.1 — Collaborative Optuna Mining (improved concurrency & robustness)
# Requirements: pip install optuna scikit-learn numpy tabulate
import os, threading, time, random, hashlib, json, sqlite3
import numpy as np
import requests, hmac, optuna
from tabulate import tabulate
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.exceptions import ConvergenceWarning
import warnings

warnings.filterwarnings("ignore", category=ConvergenceWarning)
optuna.logging.set_verbosity(optuna.logging.WARNING)

# -------------------------
# Simple mock Response class
# -------------------------
class MockResponse:
    def __init__(self, json_data=None, status_code=200):
        self._json = json_data
        self.status_code = status_code
        self.text = json.dumps(json_data) if json_data is not None else ""
    def json(self): return self._json
    def raise_for_status(self):
        if self.status_code >= 400:
            raise requests.HTTPError(f"HTTP Error {self.status_code}: {self.text}")

# -------------------------
# Server / security state
# -------------------------
PER_MINER_KEYS = {
    1: b"miner1_collab_key_v3",
    2: b"miner2_collab_key_v3",
    3: b"miner3_collab_key_v3",
    4: b"miner4_collab_key_v3"
}
model_ledger = []
ledger_lock = threading.Lock()
seen_signatures = set()
seen_lock = threading.Lock()

FRESHNESS_WINDOW_SECONDS = 60
DB_FILE = "shared_study.db"
STUDY_NAME = "ml_chain_global_study"

# -------------------------
# Helpers: signing & verify
# -------------------------
def sign_payload(key: bytes, payload: dict) -> str:
    body = json.dumps(payload, sort_keys=True, separators=(',', ':')).encode('utf-8')
    return hmac.new(key, body, hashlib.sha256).hexdigest()

def verify_payload(key: bytes, payload: dict, signature: str) -> bool:
    expected = sign_payload(key, payload)
    return hmac.compare_digest(expected, signature)

# -------------------------
# Create dataset, init study with WAL mode
# -------------------------
def create_server_assets():
    # remove previous DB so demo is repeatable
    if os.path.exists(DB_FILE):
        os.remove(DB_FILE)

    X, y = make_classification(n_samples=3000, n_features=30, n_informative=20, random_state=42)
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)
    data_payload = {
        "X_train": X_train.tolist(), "y_train": y_train.tolist(),
        "X_val": X_val.tolist(),   "y_val": y_val.tolist()
    }
    val_hash = hashlib.sha256(np.ascontiguousarray(X_val).tobytes()).hexdigest()

    # Create the sqlite file and set WAL mode to improve concurrency
    conn = sqlite3.connect(DB_FILE, timeout=30)
    try:
        conn.execute("PRAGMA journal_mode=WAL;")
        conn.commit()
    finally:
        conn.close()

    storage_url = f"sqlite:///{DB_FILE}"
    # create or load study
    optuna.create_study(storage=storage_url, study_name=STUDY_NAME, direction="maximize", load_if_exists=True)

    task_info = {
        "task_id": "collab-task-v3",
        "performance_threshold": 0.91,
        "validation_data_hash": val_hash,
        "optuna_trials_budget": 12,
        "study_storage_url": storage_url,
        "study_name": STUDY_NAME
    }
    print(f"[SERVER] Study initialized at {storage_url} (WAL enabled)")
    return task_info, data_payload

TASK_INFO, DATA_PAYLOAD = create_server_assets()

# -------------------------
# Mock server handlers (in-process)
# -------------------------
def mock_get(url, *args, **kwargs):
    if url.endswith('/get_task'):
        return MockResponse(json_data=TASK_INFO)
    if url.endswith('/get_data'):
        return MockResponse(json_data=DATA_PAYLOAD)
    if url.endswith('/get_ledger'):
        with ledger_lock:
            return MockResponse(json_data=list(model_ledger))
    return MockResponse(json_data={"error":"not found"}, status_code=404)

def mock_post(url, *args, **kwargs):
    if url.endswith('/submit_result'):
        submission = kwargs.get('json', {}) or {}
        signature = kwargs.get('headers', {}).get('X-HMAC-SIGN', "")

        # basic structural validation
        required = {'miner_id','timestamp','nonce','performance','hyperparameters','task_id','search_method'}
        if not required.issubset(set(submission.keys())):
            return MockResponse(json_data={"status":"rejected","reason":"malformed"}, status_code=400)

        miner_id = int(submission['miner_id'])
        key = PER_MINER_KEYS.get(miner_id)
        if not key:
            return MockResponse(json_data={"status":"rejected","reason":"unknown_miner"}, status_code=403)

        # freshness check
        now = int(time.time())
        if abs(now - int(submission['timestamp'])) > FRESHNESS_WINDOW_SECONDS:
            return MockResponse(json_data={"status":"rejected","reason":"stale_timestamp"}, status_code=403)

        # verify HMAC
        if not verify_payload(key, submission, signature):
            return MockResponse(json_data={"status":"rejected","reason":"bad_signature"}, status_code=403)

        # replay protection
        with seen_lock:
            if signature in seen_signatures:
                return MockResponse(json_data={"status":"rejected","reason":"replay"}, status_code=403)
            seen_signatures.add(signature)

        # accept
        with ledger_lock:
            model_ledger.append(submission)
        print(f"\n[SERVER] Accepted submission by miner {miner_id} perf={submission.get('performance'):.4f}")
        return MockResponse(json_data={"status":"accepted"}, status_code=200)

    return MockResponse(json_data={"error":"not found"}, status_code=404)

# Monkey patch requests
original_get, original_post = requests.get, requests.post
requests.get, requests.post = mock_get, mock_post

# -------------------------
# Utility: load study with retry/backoff (handles sqlite busy locks)
# -------------------------
def load_study_with_retry(storage, study_name, max_attempts=5, base_delay=0.2):
    attempt = 0
    while attempt < max_attempts:
        try:
            study = optuna.load_study(study_name=study_name, storage=storage)
            return study
        except Exception as e:
            attempt += 1
            sleep = base_delay * (2 ** attempt) + random.uniform(0, base_delay)
            print(f"[load_study] attempt {attempt} failed: {e}. retry in {sleep:.2f}s")
            time.sleep(sleep)
    raise RuntimeError("Could not load study after retries")

# -------------------------
# Collaborative miner logic (connects to shared study)
# -------------------------
def collaborative_miner_logic(miner_id: int):
    try:
        task = requests.get("mock://server/get_task").json()
        data = requests.get("mock://server/get_data").json()
    except Exception as e:
        print(f"[Miner {miner_id}] Failed to fetch task/data: {e}")
        return

    X_train, y_train = np.array(data['X_train']), np.array(data['y_train'])
    X_val, y_val = np.array(data['X_val']), np.array(data['y_val'])
    if hashlib.sha256(np.ascontiguousarray(X_val).tobytes()).hexdigest() != task['validation_data_hash']:
        print(f"[Miner {miner_id}] Data hash mismatch. Abort.")
        return

    trials = int(task.get('optuna_trials_budget', 10))
    storage = task['study_storage_url']
    study_name = task['study_name']
    print(f"[Miner {miner_id}] Connecting to shared study '{study_name}', budget {trials} trials")

    def objective(trial):
        layers = trial.suggest_categorical("layers", [(100,), (128,64), (64,32,16)])
        activation = trial.suggest_categorical("activation", ['relu','tanh'])
        lr = trial.suggest_loguniform("lr", 1e-4, 1e-2)
        alpha = trial.suggest_loguniform("alpha", 1e-6, 1e-3)
        model = MLPClassifier(hidden_layer_sizes=layers, activation=activation,
                              learning_rate_init=lr, alpha=alpha, max_iter=200,
                              early_stopping=True, n_iter_no_change=10,
                              random_state=(int(time.time()*1000) + trial.number) % (2**32))
        try:
            model.fit(X_train, y_train)
            return model.score(X_val, y_val)
        except Exception:
            return 0.0

    # load study (retry on sqlite busy)
    try:
        study = load_study_with_retry(storage, study_name)
    except Exception as e:
        print(f"[Miner {miner_id}] Failed to load study: {e}")
        return

    # run trials with small retry wrapper for optimize
    max_opt_attempts = 3
    for attempt in range(1, max_opt_attempts+1):
        try:
            study.optimize(objective, n_trials=trials, show_progress_bar=False)
            break
        except Exception as e:
            backoff = 0.2 * (2**attempt) + random.random()*0.1
            print(f"[Miner {miner_id}] optimize error (attempt {attempt}): {e}. Backing off {backoff:.2f}s")
            time.sleep(backoff)
    else:
        print(f"[Miner {miner_id}] study.optimize failed after {max_opt_attempts} attempts")
        return

    # Inspect best trial safely
    try:
        best_trial = study.best_trial
        best_perf = float(best_trial.value) if best_trial and best_trial.value is not None else 0.0
    except Exception as e:
        print(f"[Miner {miner_id}] error reading best trial: {e}")
        return

    print(f"[Miner {miner_id}] Shared study best perf now: {best_perf:.4f}")

    # Claim if threshold met
    if best_perf > float(task['performance_threshold']):
        payload = {
            "task_id": task['task_id'],
            "miner_id": miner_id,
            "performance": best_perf,
            "hyperparameters": best_trial.params if best_trial else {},
            "search_method": "Collaborative-Optuna",
            "claimed_trial_number": best_trial.number if best_trial else None,
            "timestamp": int(time.time()),
            "nonce": random.getrandbits(64)
        }
        key = PER_MINER_KEYS.get(miner_id)
        signature = sign_payload(key, payload)
        headers = {"X-HMAC-SIGN": signature}
        resp = requests.post("mock://server/submit_result", json=payload, headers=headers)
        if resp.status_code == 200 and resp.json().get('status') == 'accepted':
            print(f"[Miner {miner_id}] Claim accepted by server")
        else:
            print(f"[Miner {miner_id}] Claim rejected: {resp.json()}")
    else:
        print(f"[Miner {miner_id}] Best {best_perf:.4f} < threshold {task['performance_threshold']:.4f} — no claim")

# -------------------------
# Run simulation with threads
# -------------------------
def run_simulation(n_miners=4):
    threads = []
    for i in range(1, n_miners+1):
        t = threading.Thread(target=collaborative_miner_logic, args=(i,))
        t.start()
        threads.append(t)
        time.sleep(0.3)
    for t in threads: t.join()

    # display ledger & study stats
    print("\n=== MODEL LEDGER ===")
    with ledger_lock:
        print(tabulate([[it['miner_id'], f"{it['performance']:.4f}", it['claimed_trial_number'], it['hyperparameters']] for it in model_ledger],
                       headers=["Miner","Perf","Trial#","Hyperparams"]))

    try:
        final = optuna.load_study(study_name=STUDY_NAME, storage=f"sqlite:///{DB_FILE}")
        print(f"\nTotal shared-study trials: {len(final.trials)}")
        if final.best_trial:
            print(f"Global best perf: {final.best_trial.value:.4f}")
            print(f"Global best params: {final.best_trial.params}")
    except Exception as e:
        print(f"Could not load final study stats: {e}")

# Execute demo and restore requests
if __name__ == "__main__":
    try:
        run_simulation(n_miners=4)
    finally:
        requests.get, requests.post = original_get, original_post
        print("\nDemo finished; requests restored.")
